{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb6789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all libraries\n",
    "import sys\n",
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import cv2\n",
    "import random\n",
    "from scipy.ndimage import rotate, shift, zoom\n",
    "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
    "from skimage.filters import gaussian, median\n",
    "from scipy import ndimage\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee03c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (Run this cell FIRST in Colab)\n",
    "# If this cell fails:\n",
    "# 1. Go to Runtime -> Restart runtime\n",
    "# 2. Run this cell again and grant permissions\n",
    "# 3. Wait for \"Mounted at /content/drive\" message\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    import os\n",
    "    \n",
    "    mount_point = '/content/drive'\n",
    "    \n",
    "    # Check if already mounted\n",
    "    if os.path.ismount(mount_point):\n",
    "        print(\"✓ Google Drive is already mounted!\")\n",
    "    else:\n",
    "        print(\"Mounting Google Drive...\")\n",
    "        print(\"Please grant permissions when prompted.\")\n",
    "        drive.mount(mount_point)\n",
    "        print(\"✓ Google Drive mounted successfully!\")\n",
    "    \n",
    "    # Verify the dataset file exists\n",
    "    dataset_path = '/content/drive/MyDrive/brain_tumor_dataset.h5'\n",
    "    if os.path.exists(dataset_path):\n",
    "        print(f\"✓ Dataset found at: {dataset_path}\")\n",
    "    else:\n",
    "        print(f\"⚠ WARNING: Dataset not found at {dataset_path}\")\n",
    "        print(\"Please ensure 'brain_tumor_dataset.h5' is in your Google Drive's MyDrive folder.\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"Not running in Colab - skipping Google Drive mount\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\nIf mounting fails, try these steps:\")\n",
    "    print(\"1. Runtime -> Restart runtime\")\n",
    "    print(\"2. Clear all outputs\")\n",
    "    print(\"3. Run this cell again\")\n",
    "    print(\"4. Make sure to grant permissions when the popup appears\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428a74ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "620d1f3d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd58b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configuration management for brain tumor segmentation project.\n",
    "\"\"\"\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Project configuration settings.\"\"\"\n",
    "    \n",
    "    # Project paths\n",
    "    ENVIRONMENT = \"colab\"  # Options: \"local\", \"colab\", \"server\"\n",
    "    PROJECT_ROOT = Path('__file__').parent.parent\n",
    "    DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "    RAW_DATA_DIR = DATA_DIR / \"raw\"\n",
    "    PROCESSED_DATA_DIR = DATA_DIR / \"processed\"\n",
    "    EXTERNAL_DATA_DIR = DATA_DIR / \"external\"\n",
    "    SPLITS_DIR = DATA_DIR / \"splits\"\n",
    "    \n",
    "    MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "    CUSTOM_MODELS_DIR = MODELS_DIR / \"custom\"\n",
    "    PRETRAINED_MODELS_DIR = MODELS_DIR / \"pretrained\"\n",
    "    SAVED_MODELS_DIR = MODELS_DIR / \"saved\"\n",
    "    \n",
    "    RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "    LOGS_DIR = PROJECT_ROOT / \"logs\"\n",
    "    \n",
    "    # Dataset paths\n",
    "    HDF5_DATASET_PATH = PROJECT_ROOT / \"dataset\" / \"brain_tumor_dataset.h5\"\n",
    "    \n",
    "    # Data settings\n",
    "    IMAGE_SIZE = 256  # Standardize to 256x256\n",
    "    TRAIN_SPLIT = 0.70\n",
    "    VAL_SPLIT = 0.15\n",
    "    TEST_SPLIT = 0.15\n",
    "    RANDOM_SEED = 42\n",
    "    \n",
    "    # Preprocessing settings\n",
    "    DENOISING_METHOD = \"bilateral\"  # Options: gaussian, median, bilateral, nlm, wavelet\n",
    "    NORMALIZATION_METHOD = \"z_score\"  # Options: z_score, min_max, histogram_eq, clahe\n",
    "    \n",
    "    # Data augmentation settings\n",
    "    AUGMENTATION_ENABLED = True\n",
    "    ROTATION_RANGE = 15  # degrees\n",
    "    TRANSLATION_RANGE = 0.1  # 10% of image size\n",
    "    SCALE_RANGE = (0.9, 1.1)\n",
    "    BRIGHTNESS_RANGE = 0.1  # ±10%\n",
    "    CONTRAST_RANGE = 0.1  # ±10%\n",
    "    FLIP_PROBABILITY = 0.5\n",
    "    \n",
    "    # Training settings\n",
    "    BATCH_SIZE = 16\n",
    "    NUM_EPOCHS = 100\n",
    "    LEARNING_RATE = 1e-4\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    EARLY_STOPPING_PATIENCE = 15\n",
    "    REDUCE_LR_PATIENCE = 10\n",
    "    REDUCE_LR_FACTOR = 0.5\n",
    "    MIN_LEARNING_RATE = 1e-7\n",
    "    \n",
    "    # Model settings\n",
    "    NUM_CLASSES = 1  # Binary segmentation\n",
    "    DROPOUT_RATE = 0.2\n",
    "    \n",
    "    # Custom model settings\n",
    "    CUSTOM_MODEL_FILTERS = [64, 128, 256, 512, 1024]\n",
    "    \n",
    "    # Pre-trained model settings\n",
    "    PRETRAINED_MODEL_TYPE = \"unet\"  # Options: unet, resnet, vgg\n",
    "    PRETRAINED_ENCODER = \"resnet50\"  # For ResNet-based models\n",
    "    FREEZE_ENCODER_EPOCHS = 5  # Freeze encoder for first N epochs\n",
    "    \n",
    "    # Evaluation settings\n",
    "    EVAL_METRICS = [\"dice\", \"iou\", \"accuracy\", \"sensitivity\", \"specificity\", \"precision\", \"f1\"]\n",
    "    \n",
    "    # Hardware settings\n",
    "    NUM_WORKERS = 4\n",
    "    PIN_MEMORY = True\n",
    "    USE_MIXED_PRECISION = True\n",
    "    \n",
    "    # Logging settings\n",
    "    LOG_INTERVAL = 10  # Log every N batches\n",
    "    SAVE_INTERVAL = 5  # Save checkpoint every N epochs\n",
    "    VISUALIZE_INTERVAL = 50  # Visualize predictions every N batches\n",
    "    \n",
    "    @classmethod\n",
    "    def get_environment(cls):\n",
    "        return cls.ENVIRONMENT\n",
    "\n",
    "    @classmethod\n",
    "    def get_data_from_google_drive(cls):\n",
    "        \"\"\"Get data from Google Drive (assumes drive is already mounted).\"\"\"\n",
    "        if cls.ENVIRONMENT == \"colab\":\n",
    "            import os\n",
    "            \n",
    "            # Path to dataset in Google Drive\n",
    "            dataset_path = '/content/drive/MyDrive/brain_tumor_dataset.h5'\n",
    "            \n",
    "            # Check if the file exists\n",
    "            if os.path.exists(dataset_path):\n",
    "                print(f\"✓ Using dataset from: {dataset_path}\")\n",
    "                return dataset_path\n",
    "            else:\n",
    "                error_msg = (\n",
    "                    f\"\\n{'='*60}\\n\"\n",
    "                    f\"ERROR: Dataset not found!\\n\"\n",
    "                    f\"{'='*60}\\n\"\n",
    "                    f\"Expected location: {dataset_path}\\n\\n\"\n",
    "                    f\"Please ensure:\\n\"\n",
    "                    f\"1. You ran the 'Mount Google Drive' cell first\\n\"\n",
    "                    f\"2. The file 'brain_tumor_dataset.h5' is in your Google Drive's MyDrive folder\\n\"\n",
    "                    f\"3. The mount was successful (you should see 'Mounted at /content/drive')\\n\"\n",
    "                    f\"{'='*60}\"\n",
    "                )\n",
    "                raise FileNotFoundError(error_msg)\n",
    "                \n",
    "    @classmethod\n",
    "    def create_directories(cls):\n",
    "        \"\"\"Create all necessary directories.\"\"\"\n",
    "        directories = [\n",
    "            cls.DATA_DIR, cls.RAW_DATA_DIR, cls.PROCESSED_DATA_DIR,\n",
    "            cls.EXTERNAL_DATA_DIR, cls.SPLITS_DIR,\n",
    "            cls.MODELS_DIR, cls.CUSTOM_MODELS_DIR, cls.PRETRAINED_MODELS_DIR,\n",
    "            cls.SAVED_MODELS_DIR, cls.RESULTS_DIR, cls.LOGS_DIR\n",
    "        ]\n",
    "        for directory in directories:\n",
    "            directory.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    @classmethod\n",
    "    def get_model_path(cls, model_name: str, model_type: str = \"custom\"):\n",
    "        \"\"\"Get path for saving/loading model.\"\"\"\n",
    "        if model_type == \"custom\":\n",
    "            return cls.SAVED_MODELS_DIR / f\"{model_name}_custom.pth\"\n",
    "        else:\n",
    "            return cls.SAVED_MODELS_DIR / f\"{model_name}_pretrained.pth\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9c6cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model comparison utilities.\n",
    "\"\"\"\n",
    "\n",
    "def generate_comparison_report(\n",
    "    results_path: Path,\n",
    "    output_dir: Path\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate comprehensive comparison report.\n",
    "    \n",
    "    Args:\n",
    "        results_path: Path to evaluation results JSON\n",
    "        output_dir: Directory to save report\n",
    "    \"\"\"\n",
    "    # Load results\n",
    "    with open(results_path, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create comparison table\n",
    "    if 'custom' in results and 'pretrained' in results:\n",
    "        comparison_data = []\n",
    "        \n",
    "        for metric in ['dice', 'iou', 'accuracy', 'sensitivity', 'specificity', 'precision', 'f1']:\n",
    "            custom_val = results['custom']['metrics'].get(metric, 0)\n",
    "            pretrained_val = results['pretrained']['metrics'].get(metric, 0)\n",
    "            diff = pretrained_val - custom_val\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'Metric': metric.upper(),\n",
    "                'Custom Model': custom_val,\n",
    "                'Pre-trained Model': pretrained_val,\n",
    "                'Difference': diff,\n",
    "                'Winner': 'pretrained' if diff > 0 else 'custom'\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(comparison_data)\n",
    "        \n",
    "        # Save as CSV\n",
    "        csv_path = output_dir / \"comparison_table.csv\"\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"Comparison table saved to: {csv_path}\")\n",
    "        \n",
    "        # Save as markdown\n",
    "        md_path = output_dir / \"comparison_report.md\"\n",
    "        with open(md_path, 'w') as f:\n",
    "            f.write(\"# Model Comparison Report\\n\\n\")\n",
    "            f.write(f\"**Overall Winner**: {results.get('overall_winner', 'N/A')}\\n\\n\")\n",
    "            f.write(\"## Metrics Comparison\\n\\n\")\n",
    "            f.write(df.to_markdown(index=False))\n",
    "            f.write(\"\\n\\n\")\n",
    "            f.write(\"## Summary\\n\\n\")\n",
    "            f.write(f\"- Custom Model Best Val DSC: {results['custom'].get('best_val_dice', 'N/A')}\\n\")\n",
    "            f.write(f\"- Pre-trained Model Best Val DSC: {results['pretrained'].get('best_val_dice', 'N/A')}\\n\")\n",
    "            f.write(f\"- Custom Model Epochs: {results['custom'].get('epoch', 'N/A')}\\n\")\n",
    "            f.write(f\"- Pre-trained Model Epochs: {results['pretrained'].get('epoch', 'N/A')}\\n\")\n",
    "        \n",
    "        print(f\"Comparison report saved to: {md_path}\")\n",
    "        \n",
    "        # Create visualization\n",
    "        plot_path = output_dir / \"metrics_comparison.png\"\n",
    "        plot_metrics_comparison(\n",
    "            results['custom']['metrics'],\n",
    "            results['pretrained']['metrics'],\n",
    "            save_path=plot_path\n",
    "        )\n",
    "    \n",
    "    print(f\"\\nComparison report generated in: {output_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluation metrics for brain tumor segmentation.\n",
    "Primary metric: Dice Similarity Coefficient (DSC)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def dice_coefficient(\n",
    "    predictions: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    threshold: float = 0.5,\n",
    "    smooth: float = 1e-6\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute Dice Similarity Coefficient (DSC).\n",
    "    \n",
    "    Args:\n",
    "        predictions: Predicted masks (B, 1, H, W) with values in [0, 1]\n",
    "        targets: Ground truth masks (B, 1, H, W) with values in [0, 1]\n",
    "        threshold: Threshold for binarizing predictions\n",
    "        smooth: Smoothing factor to avoid division by zero\n",
    "    \n",
    "    Returns:\n",
    "        Dice coefficient (0-1, higher is better)\n",
    "    \"\"\"\n",
    "    # Binarize predictions\n",
    "    predictions_binary = (predictions > threshold).float()\n",
    "    targets_binary = targets.float()\n",
    "    \n",
    "    # Flatten tensors\n",
    "    predictions_flat = predictions_binary.view(-1)\n",
    "    targets_flat = targets_binary.view(-1)\n",
    "    \n",
    "    # Compute intersection and union\n",
    "    intersection = (predictions_flat * targets_flat).sum()\n",
    "    dice = (2.0 * intersection + smooth) / (\n",
    "        predictions_flat.sum() + targets_flat.sum() + smooth\n",
    "    )\n",
    "    \n",
    "    return dice.item()\n",
    "\n",
    "\n",
    "def iou_score(\n",
    "    predictions: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    threshold: float = 0.5,\n",
    "    smooth: float = 1e-6\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute Intersection over Union (IoU).\n",
    "    \n",
    "    Args:\n",
    "        predictions: Predicted masks\n",
    "        targets: Ground truth masks\n",
    "        threshold: Threshold for binarizing predictions\n",
    "        smooth: Smoothing factor\n",
    "    \n",
    "    Returns:\n",
    "        IoU score (0-1, higher is better)\n",
    "    \"\"\"\n",
    "    # Binarize predictions\n",
    "    predictions_binary = (predictions > threshold).float()\n",
    "    targets_binary = targets.float()\n",
    "    \n",
    "    # Flatten tensors\n",
    "    predictions_flat = predictions_binary.view(-1)\n",
    "    targets_flat = targets_binary.view(-1)\n",
    "    \n",
    "    # Compute intersection and union\n",
    "    intersection = (predictions_flat * targets_flat).sum()\n",
    "    union = predictions_flat.sum() + targets_flat.sum() - intersection\n",
    "    \n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    \n",
    "    return iou.item()\n",
    "\n",
    "\n",
    "def pixel_accuracy(\n",
    "    predictions: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    threshold: float = 0.5\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute pixel accuracy.\n",
    "    \n",
    "    Args:\n",
    "        predictions: Predicted masks\n",
    "        targets: Ground truth masks\n",
    "        threshold: Threshold for binarizing predictions\n",
    "    \n",
    "    Returns:\n",
    "        Pixel accuracy (0-1, higher is better)\n",
    "    \"\"\"\n",
    "    predictions_binary = (predictions > threshold).float()\n",
    "    targets_binary = targets.float()\n",
    "    \n",
    "    correct = (predictions_binary == targets_binary).float()\n",
    "    accuracy = correct.sum() / correct.numel()\n",
    "    \n",
    "    return accuracy.item()\n",
    "\n",
    "\n",
    "def sensitivity(\n",
    "    predictions: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    threshold: float = 0.5,\n",
    "    smooth: float = 1e-6\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute sensitivity (recall, true positive rate).\n",
    "    \n",
    "    Args:\n",
    "        predictions: Predicted masks\n",
    "        targets: Ground truth masks\n",
    "        threshold: Threshold for binarizing predictions\n",
    "        smooth: Smoothing factor\n",
    "    \n",
    "    Returns:\n",
    "        Sensitivity (0-1, higher is better)\n",
    "    \"\"\"\n",
    "    predictions_binary = (predictions > threshold).float()\n",
    "    targets_binary = targets.float()\n",
    "    \n",
    "    # True positives and false negatives\n",
    "    tp = ((predictions_binary == 1) & (targets_binary == 1)).float().sum()\n",
    "    fn = ((predictions_binary == 0) & (targets_binary == 1)).float().sum()\n",
    "    \n",
    "    sensitivity = (tp + smooth) / (tp + fn + smooth)\n",
    "    \n",
    "    return sensitivity.item()\n",
    "\n",
    "\n",
    "def specificity(\n",
    "    predictions: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    threshold: float = 0.5,\n",
    "    smooth: float = 1e-6\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute specificity (true negative rate).\n",
    "    \n",
    "    Args:\n",
    "        predictions: Predicted masks\n",
    "        targets: Ground truth masks\n",
    "        threshold: Threshold for binarizing predictions\n",
    "        smooth: Smoothing factor\n",
    "    \n",
    "    Returns:\n",
    "        Specificity (0-1, higher is better)\n",
    "    \"\"\"\n",
    "    predictions_binary = (predictions > threshold).float()\n",
    "    targets_binary = targets.float()\n",
    "    \n",
    "    # True negatives and false positives\n",
    "    tn = ((predictions_binary == 0) & (targets_binary == 0)).float().sum()\n",
    "    fp = ((predictions_binary == 1) & (targets_binary == 0)).float().sum()\n",
    "    \n",
    "    specificity = (tn + smooth) / (tn + fp + smooth)\n",
    "    \n",
    "    return specificity.item()\n",
    "\n",
    "\n",
    "def precision_score(\n",
    "    predictions: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    threshold: float = 0.5,\n",
    "    smooth: float = 1e-6\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute precision (positive predictive value).\n",
    "    \n",
    "    Args:\n",
    "        predictions: Predicted masks\n",
    "        targets: Ground truth masks\n",
    "        threshold: Threshold for binarizing predictions\n",
    "        smooth: Smoothing factor\n",
    "    \n",
    "    Returns:\n",
    "        Precision (0-1, higher is better)\n",
    "    \"\"\"\n",
    "    predictions_binary = (predictions > threshold).float()\n",
    "    targets_binary = targets.float()\n",
    "    \n",
    "    # True positives and false positives\n",
    "    tp = ((predictions_binary == 1) & (targets_binary == 1)).float().sum()\n",
    "    fp = ((predictions_binary == 1) & (targets_binary == 0)).float().sum()\n",
    "    \n",
    "    precision = (tp + smooth) / (tp + fp + smooth)\n",
    "    \n",
    "    return precision.item()\n",
    "\n",
    "\n",
    "def f1_score(\n",
    "    predictions: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    threshold: float = 0.5,\n",
    "    smooth: float = 1e-6\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute F1 score (harmonic mean of precision and recall).\n",
    "    \n",
    "    Args:\n",
    "        predictions: Predicted masks\n",
    "        targets: Ground truth masks\n",
    "        threshold: Threshold for binarizing predictions\n",
    "        smooth: Smoothing factor\n",
    "    \n",
    "    Returns:\n",
    "        F1 score (0-1, higher is better)\n",
    "    \"\"\"\n",
    "    prec = precision_score(predictions, targets, threshold, smooth)\n",
    "    sens = sensitivity(predictions, targets, threshold, smooth)\n",
    "    \n",
    "    f1 = (2 * prec * sens + smooth) / (prec + sens + smooth)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "\n",
    "def compute_all_metrics(\n",
    "    predictions: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    threshold: float = 0.5\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute all evaluation metrics.\n",
    "    \n",
    "    Args:\n",
    "        predictions: Predicted masks\n",
    "        targets: Ground truth masks\n",
    "        threshold: Threshold for binarizing predictions\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of metric names and values\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'dice': dice_coefficient(predictions, targets, threshold),\n",
    "        'iou': iou_score(predictions, targets, threshold),\n",
    "        'accuracy': pixel_accuracy(predictions, targets, threshold),\n",
    "        'sensitivity': sensitivity(predictions, targets, threshold),\n",
    "        'specificity': specificity(predictions, targets, threshold),\n",
    "        'precision': precision_score(predictions, targets, threshold),\n",
    "        'f1': f1_score(predictions, targets, threshold)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    device: torch.device,\n",
    "    threshold: float = 0.5\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate model on a dataset.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        dataloader: DataLoader for evaluation\n",
    "        device: Device to run evaluation on\n",
    "        threshold: Threshold for binarizing predictions\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of average metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_metrics = {\n",
    "        'dice': [],\n",
    "        'iou': [],\n",
    "        'accuracy': [],\n",
    "        'sensitivity': [],\n",
    "        'specificity': [],\n",
    "        'precision': [],\n",
    "        'f1': []\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images = batch['image'].to(device)\n",
    "            masks = batch['mask'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = model(images)\n",
    "            \n",
    "            # Compute metrics for this batch\n",
    "            batch_metrics = compute_all_metrics(predictions, masks, threshold)\n",
    "            \n",
    "            # Accumulate\n",
    "            for key in all_metrics:\n",
    "                all_metrics[key].append(batch_metrics[key])\n",
    "    \n",
    "    # Compute averages\n",
    "    avg_metrics = {key: np.mean(values) for key, values in all_metrics.items()}\n",
    "    \n",
    "    return avg_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76638200",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualization utilities for model predictions and results.\n",
    "\"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import Optional, List\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def visualize_predictions(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    device: torch.device,\n",
    "    num_samples: int = 8,\n",
    "    threshold: float = 0.5,\n",
    "    save_path: Optional[Path] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize model predictions on sample images.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        dataloader: DataLoader for samples\n",
    "        device: Device to run inference on\n",
    "        num_samples: Number of samples to visualize\n",
    "        threshold: Threshold for binarizing predictions\n",
    "        save_path: Path to save visualization\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch\n",
    "    batch = next(iter(dataloader))\n",
    "    images = batch['image'].to(device)\n",
    "    masks = batch['mask'].to(device)\n",
    "    \n",
    "    # Limit to num_samples\n",
    "    images = images[:num_samples]\n",
    "    masks = masks[:num_samples]\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        predictions = model(images)\n",
    "        predictions_binary = (predictions > threshold).float()\n",
    "    \n",
    "    # Move to CPU and convert to numpy\n",
    "    images = images.cpu().numpy()\n",
    "    masks = masks.cpu().numpy()\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    predictions_binary = predictions_binary.cpu().numpy()\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4 * num_samples))\n",
    "    \n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Original image\n",
    "        axes[i, 0].imshow(images[i, 0], cmap='gray')\n",
    "        axes[i, 0].set_title('Original Image')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Ground truth mask\n",
    "        axes[i, 1].imshow(masks[i, 0], cmap='gray')\n",
    "        axes[i, 1].set_title('Ground Truth')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Predicted mask (probability)\n",
    "        axes[i, 2].imshow(predictions[i, 0], cmap='hot')\n",
    "        axes[i, 2].set_title('Prediction (Probability)')\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        # Predicted mask (binary)\n",
    "        axes[i, 3].imshow(predictions_binary[i, 0], cmap='gray')\n",
    "        axes[i, 3].set_title('Prediction (Binary)')\n",
    "        axes[i, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Visualization saved to {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_training_curves(\n",
    "    train_losses: List[float],\n",
    "    val_dice_scores: List[float],\n",
    "    save_path: Optional[Path] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot training curves.\n",
    "    \n",
    "    Args:\n",
    "        train_losses: List of training losses per epoch\n",
    "        val_dice_scores: List of validation DSC scores per epoch\n",
    "        save_path: Path to save plot\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Training loss\n",
    "    ax1.plot(train_losses, label='Training Loss', color='blue')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Validation DSC\n",
    "    ax2.plot(val_dice_scores, label='Validation DSC', color='green')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Dice Similarity Coefficient')\n",
    "    ax2.set_title('Validation DSC')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Training curves saved to {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_metrics_comparison(\n",
    "    custom_metrics: dict,\n",
    "    pretrained_metrics: dict,\n",
    "    save_path: Optional[Path] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot comparison of metrics between models.\n",
    "    \n",
    "    Args:\n",
    "        custom_metrics: Metrics dictionary for custom model\n",
    "        pretrained_metrics: Metrics dictionary for pre-trained model\n",
    "        save_path: Path to save plot\n",
    "    \"\"\"\n",
    "    metrics_names = ['dice', 'iou', 'accuracy', 'sensitivity', 'specificity', 'precision', 'f1']\n",
    "    \n",
    "    custom_values = [custom_metrics.get(m, 0) for m in metrics_names]\n",
    "    pretrained_values = [pretrained_metrics.get(m, 0) for m in metrics_names]\n",
    "    \n",
    "    x = np.arange(len(metrics_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, custom_values, width, label='Custom Model', alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, pretrained_values, width, label='Pre-trained Model', alpha=0.8)\n",
    "    \n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Model Comparison - Evaluation Metrics')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([m.upper() for m in metrics_names], rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.set_ylim([0, 1.1])\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.3f}',\n",
    "                   ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Comparison plot saved to {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def create_confusion_matrix_plot(\n",
    "    predictions: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    threshold: float = 0.5,\n",
    "    save_path: Optional[Path] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create and plot confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "        predictions: Predicted masks\n",
    "        targets: Ground truth masks\n",
    "        threshold: Threshold for binarizing predictions\n",
    "        save_path: Path to save plot\n",
    "    \"\"\"\n",
    "    predictions_binary = (predictions > threshold).float()\n",
    "    targets_binary = targets.float()\n",
    "    \n",
    "    # Flatten\n",
    "    pred_flat = predictions_binary.view(-1).cpu().numpy()\n",
    "    target_flat = targets_binary.view(-1).cpu().numpy()\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(target_flat, pred_flat, labels=[0, 1])\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['Background', 'Tumor'],\n",
    "                yticklabels=['Background', 'Tumor'])\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Confusion matrix saved to {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data augmentation transforms for training.\n",
    "\"\"\"\n",
    "class AugmentationTransform:\n",
    "    \"\"\"Apply augmentation to both image and mask.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        rotation_range: float = 15,\n",
    "        translation_range: float = 0.1,\n",
    "        scale_range: Tuple[float, float] = (0.9, 1.1),\n",
    "        brightness_range: float = 0.1,\n",
    "        contrast_range: float = 0.1,\n",
    "        flip_probability: float = 0.5,\n",
    "        elastic_deformation: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize augmentation parameters.\n",
    "        \n",
    "        Args:\n",
    "            rotation_range: Maximum rotation in degrees\n",
    "            translation_range: Maximum translation as fraction of image size\n",
    "            scale_range: (min, max) scaling factors\n",
    "            brightness_range: Maximum brightness adjustment (±)\n",
    "            contrast_range: Maximum contrast adjustment (±)\n",
    "            flip_probability: Probability of horizontal/vertical flip\n",
    "            elastic_deformation: Whether to apply elastic deformation\n",
    "        \"\"\"\n",
    "        self.rotation_range = rotation_range\n",
    "        self.translation_range = translation_range\n",
    "        self.scale_range = scale_range\n",
    "        self.brightness_range = brightness_range\n",
    "        self.contrast_range = contrast_range\n",
    "        self.flip_probability = flip_probability\n",
    "        self.elastic_deformation = elastic_deformation\n",
    "    \n",
    "    def __call__(self, sample: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Apply augmentation to sample.\n",
    "        \n",
    "        Args:\n",
    "            sample: Dictionary with 'image' and 'mask' keys\n",
    "        \n",
    "        Returns:\n",
    "            Augmented sample\n",
    "        \"\"\"\n",
    "        image = sample['image'].copy()\n",
    "        mask = sample['mask'].copy()\n",
    "        \n",
    "        # Random rotation\n",
    "        if self.rotation_range > 0:\n",
    "            angle = random.uniform(-self.rotation_range, self.rotation_range)\n",
    "            image = self._rotate(image, angle)\n",
    "            mask = self._rotate(mask, angle)\n",
    "        \n",
    "        # Random translation\n",
    "        if self.translation_range > 0:\n",
    "            h, w = image.shape[:2]\n",
    "            tx = random.uniform(-self.translation_range, self.translation_range) * w\n",
    "            ty = random.uniform(-self.translation_range, self.translation_range) * h\n",
    "            image = self._translate(image, tx, ty)\n",
    "            mask = self._translate(mask, tx, ty)\n",
    "        \n",
    "        # Random scaling\n",
    "        if self.scale_range[0] != 1.0 or self.scale_range[1] != 1.0:\n",
    "            scale = random.uniform(self.scale_range[0], self.scale_range[1])\n",
    "            image = self._scale(image, scale)\n",
    "            mask = self._scale(mask, scale)\n",
    "        \n",
    "        # Random flips\n",
    "        if random.random() < self.flip_probability:\n",
    "            if random.random() < 0.5:\n",
    "                image = np.fliplr(image)\n",
    "                mask = np.fliplr(mask)\n",
    "            else:\n",
    "                image = np.flipud(image)\n",
    "                mask = np.flipud(mask)\n",
    "        \n",
    "        # Intensity augmentations (only for image)\n",
    "        if self.brightness_range > 0:\n",
    "            brightness = random.uniform(-self.brightness_range, self.brightness_range)\n",
    "            image = self._adjust_brightness(image, brightness)\n",
    "        \n",
    "        if self.contrast_range > 0:\n",
    "            contrast = random.uniform(-self.contrast_range, self.contrast_range)\n",
    "            image = self._adjust_contrast(image, contrast)\n",
    "        \n",
    "        # Elastic deformation\n",
    "        if self.elastic_deformation:\n",
    "            image, mask = self._elastic_deform(image, mask)\n",
    "        \n",
    "        return {'image': image, 'mask': mask}\n",
    "    \n",
    "    def _rotate(self, image: np.ndarray, angle: float) -> np.ndarray:\n",
    "        \"\"\"Rotate image.\"\"\"\n",
    "        h, w = image.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        \n",
    "        if image.max() <= 1.0:\n",
    "            image_uint8 = (image * 255).astype(np.uint8)\n",
    "        else:\n",
    "            image_uint8 = image.astype(np.uint8)\n",
    "        \n",
    "        rotated = cv2.warpAffine(\n",
    "            image_uint8, M, (w, h),\n",
    "            flags=cv2.INTER_LINEAR,\n",
    "            borderMode=cv2.BORDER_REFLECT\n",
    "        )\n",
    "        \n",
    "        return rotated.astype(np.float32) / 255.0 if image.max() <= 1.0 else rotated.astype(np.float32)\n",
    "    \n",
    "    def _translate(self, image: np.ndarray, tx: float, ty: float) -> np.ndarray:\n",
    "        \"\"\"Translate image.\"\"\"\n",
    "        h, w = image.shape[:2]\n",
    "        M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "        \n",
    "        if image.max() <= 1.0:\n",
    "            image_uint8 = (image * 255).astype(np.uint8)\n",
    "        else:\n",
    "            image_uint8 = image.astype(np.uint8)\n",
    "        \n",
    "        translated = cv2.warpAffine(\n",
    "            image_uint8, M, (w, h),\n",
    "            flags=cv2.INTER_LINEAR,\n",
    "            borderMode=cv2.BORDER_REFLECT\n",
    "        )\n",
    "        \n",
    "        return translated.astype(np.float32) / 255.0 if image.max() <= 1.0 else translated.astype(np.float32)\n",
    "    \n",
    "    def _scale(self, image: np.ndarray, scale: float) -> np.ndarray:\n",
    "        \"\"\"Scale image.\"\"\"\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = int(h * scale), int(w * scale)\n",
    "        \n",
    "        if image.max() <= 1.0:\n",
    "            image_uint8 = (image * 255).astype(np.uint8)\n",
    "        else:\n",
    "            image_uint8 = image.astype(np.uint8)\n",
    "        \n",
    "        scaled = cv2.resize(image_uint8, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Crop or pad to original size\n",
    "        if scale > 1.0:\n",
    "            # Crop center\n",
    "            start_h = (new_h - h) // 2\n",
    "            start_w = (new_w - w) // 2\n",
    "            scaled = scaled[start_h:start_h+h, start_w:start_w+w]\n",
    "        else:\n",
    "            # Pad\n",
    "            pad_h = (h - new_h) // 2\n",
    "            pad_w = (w - new_w) // 2\n",
    "            scaled = np.pad(scaled, ((pad_h, h-new_h-pad_h), (pad_w, w-new_w-pad_w)), mode='reflect')\n",
    "        \n",
    "        return scaled.astype(np.float32) / 255.0 if image.max() <= 1.0 else scaled.astype(np.float32)\n",
    "    \n",
    "    def _adjust_brightness(self, image: np.ndarray, brightness: float) -> np.ndarray:\n",
    "        \"\"\"Adjust brightness.\"\"\"\n",
    "        return np.clip(image + brightness, 0, 1)\n",
    "    \n",
    "    def _adjust_contrast(self, image: np.ndarray, contrast: float) -> np.ndarray:\n",
    "        \"\"\"Adjust contrast.\"\"\"\n",
    "        mean = np.mean(image)\n",
    "        return np.clip((image - mean) * (1 + contrast) + mean, 0, 1)\n",
    "    \n",
    "    def _elastic_deform(self, image: np.ndarray, mask: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Apply elastic deformation.\"\"\"\n",
    "        # Simplified elastic deformation\n",
    "        alpha = random.uniform(50, 150)\n",
    "        sigma = random.uniform(5, 10)\n",
    "        \n",
    "        h, w = image.shape[:2]\n",
    "        dx = np.random.randn(h, w) * alpha\n",
    "        dy = np.random.randn(h, w) * alpha\n",
    "        \n",
    "        # Smooth the displacement fields\n",
    "        from scipy.ndimage import gaussian_filter\n",
    "        dx = gaussian_filter(dx, sigma)\n",
    "        dy = gaussian_filter(dy, sigma)\n",
    "        \n",
    "        # Create coordinate grids\n",
    "        x, y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "        x_new = np.clip(x + dx, 0, w - 1).astype(np.float32)\n",
    "        y_new = np.clip(y + dy, 0, h - 1).astype(np.float32)\n",
    "        \n",
    "        # Apply deformation\n",
    "        if image.max() <= 1.0:\n",
    "            image_uint8 = (image * 255).astype(np.uint8)\n",
    "        else:\n",
    "            image_uint8 = image.astype(np.uint8)\n",
    "        \n",
    "        image_deformed = cv2.remap(\n",
    "            image_uint8, x_new, y_new,\n",
    "            cv2.INTER_LINEAR,\n",
    "            borderMode=cv2.BORDER_REFLECT\n",
    "        )\n",
    "        \n",
    "        if mask.max() <= 1.0:\n",
    "            mask_uint8 = (mask * 255).astype(np.uint8)\n",
    "        else:\n",
    "            mask_uint8 = mask.astype(np.uint8)\n",
    "        \n",
    "        mask_deformed = cv2.remap(\n",
    "            mask_uint8, x_new, y_new,\n",
    "            cv2.INTER_LINEAR,\n",
    "            borderMode=cv2.BORDER_REFLECT\n",
    "        )\n",
    "        \n",
    "        return (\n",
    "            image_deformed.astype(np.float32) / 255.0 if image.max() <= 1.0 else image_deformed.astype(np.float32),\n",
    "            mask_deformed.astype(np.float32) / 255.0 if mask.max() <= 1.0 else mask_deformed.astype(np.float32)\n",
    "        )\n",
    "\n",
    "\n",
    "class PreprocessingTransform:\n",
    "    \"\"\"Apply preprocessing (denoising, normalization, resizing) to images.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        target_size: int = 256,\n",
    "        denoising_method: Optional[str] = None,\n",
    "        normalization_method: str = \"z_score\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize preprocessing transform.\n",
    "        \n",
    "        Args:\n",
    "            target_size: Target image size (square)\n",
    "            denoising_method: Denoising method (None to skip)\n",
    "            normalization_method: Normalization method\n",
    "        \"\"\"\n",
    "        self.target_size = target_size\n",
    "        self.denoising_method = denoising_method\n",
    "        self.normalization_method = normalization_method\n",
    "    \n",
    "    def __call__(self, sample: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Apply preprocessing to sample.\n",
    "        \n",
    "        Args:\n",
    "            sample: Dictionary with 'image' and 'mask' keys\n",
    "        \n",
    "        Returns:\n",
    "            Preprocessed sample\n",
    "        \"\"\"\n",
    "        image = sample['image'].copy()\n",
    "        mask = sample['mask'].copy()\n",
    "        \n",
    "        # Resize if needed\n",
    "        if image.shape[0] != self.target_size or image.shape[1] != self.target_size:\n",
    "            image = self._resize(image, self.target_size)\n",
    "            mask = self._resize(mask, self.target_size, is_mask=True)\n",
    "        \n",
    "        # Denoising (only for image)\n",
    "        if self.denoising_method:\n",
    "            from preprocessing.denoising import apply_denoising\n",
    "            image = apply_denoising(image, method=self.denoising_method)\n",
    "        \n",
    "        # Normalization (only for image)\n",
    "        if self.normalization_method:\n",
    "            from preprocessing.normalization import apply_normalization\n",
    "            image = apply_normalization(image, method=self.normalization_method)\n",
    "        \n",
    "        # Ensure mask is binary\n",
    "        mask = (mask > 0.5).astype(np.float32)\n",
    "        \n",
    "        return {'image': image, 'mask': mask}\n",
    "    \n",
    "    def _resize(self, image: np.ndarray, target_size: int, is_mask: bool = False) -> np.ndarray:\n",
    "        \"\"\"Resize image to target size.\"\"\"\n",
    "        if image.max() <= 1.0 and not is_mask:\n",
    "            image_uint8 = (image * 255).astype(np.uint8)\n",
    "        elif is_mask:\n",
    "            image_uint8 = (image * 255).astype(np.uint8)\n",
    "        else:\n",
    "            image_uint8 = image.astype(np.uint8)\n",
    "        \n",
    "        interpolation = cv2.INTER_NEAREST if is_mask else cv2.INTER_LINEAR\n",
    "        resized = cv2.resize(image_uint8, (target_size, target_size), interpolation=interpolation)\n",
    "        \n",
    "        if image.max() <= 1.0 or is_mask:\n",
    "            return resized.astype(np.float32) / 255.0\n",
    "        else:\n",
    "            return resized.astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c19f8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Image denoising methods for MRI brain images.\n",
    "\"\"\"\n",
    "\n",
    "def gaussian_denoise(\n",
    "    image: np.ndarray,\n",
    "    kernel_size: int = 5,\n",
    "    sigma: float = 1.0\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply Gaussian filtering for denoising.\n",
    "    \n",
    "    Args:\n",
    "        image: Input grayscale image\n",
    "        kernel_size: Size of Gaussian kernel (must be odd)\n",
    "        sigma: Standard deviation of Gaussian kernel\n",
    "    \n",
    "    Returns:\n",
    "        Denoised image\n",
    "    \"\"\"\n",
    "    if kernel_size % 2 == 0:\n",
    "        kernel_size += 1\n",
    "    \n",
    "    return gaussian(image, sigma=sigma, mode='reflect')\n",
    "\n",
    "\n",
    "def median_denoise(\n",
    "    image: np.ndarray,\n",
    "    kernel_size: int = 5\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply median filtering for denoising.\n",
    "    \n",
    "    Args:\n",
    "        image: Input grayscale image\n",
    "        kernel_size: Size of median filter kernel (must be odd)\n",
    "    \n",
    "    Returns:\n",
    "        Denoised image\n",
    "    \"\"\"\n",
    "    if kernel_size % 2 == 0:\n",
    "        kernel_size += 1\n",
    "    \n",
    "    return median(image, selem=np.ones((kernel_size, kernel_size)))\n",
    "\n",
    "\n",
    "def bilateral_denoise(\n",
    "    image: np.ndarray,\n",
    "    d: int = 9,\n",
    "    sigma_color: float = 75.0,\n",
    "    sigma_space: float = 75.0\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply bilateral filtering for edge-preserving denoising.\n",
    "    \n",
    "    Args:\n",
    "        image: Input grayscale image (0-255 range)\n",
    "        d: Diameter of pixel neighborhood\n",
    "        sigma_color: Filter sigma in the color space\n",
    "        sigma_space: Filter sigma in the coordinate space\n",
    "    \n",
    "    Returns:\n",
    "        Denoised image\n",
    "    \"\"\"\n",
    "    # Convert to uint8 if needed\n",
    "    if image.max() <= 1.0:\n",
    "        image_uint8 = (image * 255).astype(np.uint8)\n",
    "    else:\n",
    "        image_uint8 = image.astype(np.uint8)\n",
    "    \n",
    "    denoised = cv2.bilateralFilter(\n",
    "        image_uint8, d, sigma_color, sigma_space\n",
    "    )\n",
    "    \n",
    "    # Convert back to float\n",
    "    return denoised.astype(np.float32) / 255.0 if image.max() <= 1.0 else denoised.astype(np.float32)\n",
    "\n",
    "\n",
    "def nlm_denoise(\n",
    "    image: np.ndarray,\n",
    "    patch_size: int = 5,\n",
    "    patch_distance: int = 6,\n",
    "    h: Optional[float] = None\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply Non-Local Means denoising.\n",
    "    \n",
    "    Args:\n",
    "        image: Input grayscale image\n",
    "        patch_size: Size of patches used for denoising\n",
    "        patch_distance: Max distance to search for patches\n",
    "        h: Cut-off distance for the exponential function (auto-estimated if None)\n",
    "    \n",
    "    Returns:\n",
    "        Denoised image\n",
    "    \"\"\"\n",
    "    # Estimate noise if h not provided\n",
    "    if h is None:\n",
    "        sigma_est = estimate_sigma(image, multichannel=False)\n",
    "        h = 0.8 * sigma_est\n",
    "    \n",
    "    denoised = denoise_nl_means(\n",
    "        image,\n",
    "        patch_size=patch_size,\n",
    "        patch_distance=patch_distance,\n",
    "        h=h,\n",
    "        multichannel=False,\n",
    "        fast_mode=True\n",
    "    )\n",
    "    \n",
    "    return denoised\n",
    "\n",
    "\n",
    "def wavelet_denoise(\n",
    "    image: np.ndarray,\n",
    "    wavelet: str = 'db4',\n",
    "    mode: str = 'soft',\n",
    "    threshold: Optional[float] = None\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply wavelet denoising.\n",
    "    \n",
    "    Args:\n",
    "        image: Input grayscale image\n",
    "        wavelet: Wavelet type (e.g., 'db4', 'haar', 'bior2.2')\n",
    "        mode: Thresholding mode ('soft' or 'hard')\n",
    "        threshold: Threshold value (auto-estimated if None)\n",
    "    \n",
    "    Returns:\n",
    "        Denoised image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import pywt\n",
    "    except ImportError:\n",
    "        raise ImportError(\"pywt (PyWavelets) is required for wavelet denoising\")\n",
    "    \n",
    "    # Decompose\n",
    "    coeffs = pywt.wavedec2(image, wavelet, mode='symmetric')\n",
    "    \n",
    "    # Estimate threshold if not provided\n",
    "    if threshold is None:\n",
    "        # Use universal threshold\n",
    "        sigma = np.median(np.abs(coeffs[-1])) / 0.6745\n",
    "        threshold = sigma * np.sqrt(2 * np.log(image.size))\n",
    "    \n",
    "    # Threshold coefficients\n",
    "    coeffs_thresh = list(coeffs)\n",
    "    coeffs_thresh[0] = pywt.threshold(coeffs[0], threshold, mode=mode)\n",
    "    for i in range(1, len(coeffs)):\n",
    "        coeffs_thresh[i] = tuple(\n",
    "            pywt.threshold(detail, threshold, mode=mode)\n",
    "            for detail in coeffs[i]\n",
    "        )\n",
    "    \n",
    "    # Reconstruct\n",
    "    denoised = pywt.waverec2(coeffs_thresh, wavelet, mode='symmetric')\n",
    "    \n",
    "    return denoised\n",
    "\n",
    "\n",
    "def apply_denoising(\n",
    "    image: np.ndarray,\n",
    "    method: str = \"bilateral\",\n",
    "    **kwargs\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply denoising using specified method.\n",
    "    \n",
    "    Args:\n",
    "        image: Input grayscale image\n",
    "        method: Denoising method ('gaussian', 'median', 'bilateral', 'nlm', 'wavelet')\n",
    "        **kwargs: Additional arguments for specific denoising method\n",
    "    \n",
    "    Returns:\n",
    "        Denoised image\n",
    "    \"\"\"\n",
    "    methods = {\n",
    "        'gaussian': gaussian_denoise,\n",
    "        'median': median_denoise,\n",
    "        'bilateral': bilateral_denoise,\n",
    "        'nlm': nlm_denoise,\n",
    "        'wavelet': wavelet_denoise\n",
    "    }\n",
    "    \n",
    "    if method not in methods:\n",
    "        raise ValueError(f\"Unknown denoising method: {method}. Choose from {list(methods.keys())}\")\n",
    "    \n",
    "    return methods[method](image, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca00cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HDF5 dataset loader for brain tumor MRI images.\n",
    "\"\"\"\n",
    "# import h5py\n",
    "# import numpy as np\n",
    "# import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from typing import Tuple, List, Dict, Optional\n",
    "# from pathlib import Path\n",
    "# import json\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from utils.config import Config\n",
    "\n",
    "\n",
    "class BrainTumorDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for brain tumor HDF5 data.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        hdf5_path: Path,\n",
    "        patient_ids: List[str],\n",
    "        transform=None,\n",
    "        return_label: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize dataset.\n",
    "        \n",
    "        Args:\n",
    "            hdf5_path: Path to HDF5 file\n",
    "            patient_ids: List of patient group IDs to use\n",
    "            transform: Optional transform to apply to image and mask\n",
    "            return_label: Whether to return tumor type label\n",
    "        \"\"\"\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.patient_ids = patient_ids\n",
    "        self.transform = transform\n",
    "        self.return_label = return_label\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.patient_ids)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict:\n",
    "        \"\"\"Get a single sample.\"\"\"\n",
    "        patient_id = self.patient_ids[idx]\n",
    "        \n",
    "        with h5py.File(self.hdf5_path, 'r') as f:\n",
    "            group = f[patient_id]\n",
    "            image = np.array(group['image'], dtype=np.float32)\n",
    "            mask = np.array(group['tumor_mask'], dtype=np.float32)\n",
    "            \n",
    "            if self.return_label:\n",
    "                label = int(group['label'][()])\n",
    "            else:\n",
    "                label = None\n",
    "        \n",
    "        # Normalize image to [0, 1] range\n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        # Ensure mask is binary [0, 1]\n",
    "        mask = (mask > 0.5).astype(np.float32)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            transformed = self.transform({'image': image, 'mask': mask})\n",
    "            image = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "        \n",
    "        # Convert to tensors\n",
    "        image = torch.from_numpy(image).unsqueeze(0)  # Add channel dimension\n",
    "        mask = torch.from_numpy(mask).unsqueeze(0)  # Add channel dimension\n",
    "        \n",
    "        result = {\n",
    "            'image': image,\n",
    "            'mask': mask,\n",
    "            'patient_id': patient_id\n",
    "        }\n",
    "        \n",
    "        if self.return_label:\n",
    "            result['label'] = label\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "class HDF5DatasetExplorer:\n",
    "    \"\"\"Utility class to explore HDF5 dataset structure.\"\"\"\n",
    "    \n",
    "    def __init__(self, hdf5_path: Path):\n",
    "        self.hdf5_path = hdf5_path\n",
    "    \n",
    "    def explore(self) -> Dict:\n",
    "        \"\"\"Explore dataset and return statistics.\"\"\"\n",
    "        stats = {\n",
    "            'total_patients': 0,\n",
    "            'patient_ids': [],\n",
    "            'image_shapes': [],\n",
    "            'mask_shapes': [],\n",
    "            'labels': [],\n",
    "            'label_distribution': {}\n",
    "        }\n",
    "        \n",
    "        with h5py.File(self.hdf5_path, 'r') as f:\n",
    "            patient_ids = list(f.keys())\n",
    "            stats['total_patients'] = len(patient_ids)\n",
    "            stats['patient_ids'] = patient_ids\n",
    "            \n",
    "            for patient_id in patient_ids:\n",
    "                group = f[patient_id]\n",
    "                \n",
    "                # Get image shape\n",
    "                image = group['image']\n",
    "                stats['image_shapes'].append(image.shape)\n",
    "                \n",
    "                # Get mask shape\n",
    "                mask = group['tumor_mask']\n",
    "                stats['mask_shapes'].append(mask.shape)\n",
    "                \n",
    "                # Get label\n",
    "                label = int(group['label'][()])\n",
    "                stats['labels'].append(label)\n",
    "                \n",
    "                # Update label distribution\n",
    "                label_name = {1: 'Meningioma', 2: 'Glioma', 3: 'Pituitary'}[label]\n",
    "                stats['label_distribution'][label_name] = \\\n",
    "                    stats['label_distribution'].get(label_name, 0) + 1\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Print dataset summary.\"\"\"\n",
    "        stats = self.explore()\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"Dataset Summary\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Total Patients: {stats['total_patients']}\")\n",
    "        print(f\"\\nLabel Distribution:\")\n",
    "        for label, count in stats['label_distribution'].items():\n",
    "            percentage = (count / stats['total_patients']) * 100\n",
    "            print(f\"  {label}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nImage Shapes:\")\n",
    "        unique_shapes = set(stats['image_shapes'])\n",
    "        for shape in unique_shapes:\n",
    "            count = stats['image_shapes'].count(shape)\n",
    "            print(f\"  {shape}: {count} images\")\n",
    "        \n",
    "        print(f\"\\nMask Shapes:\")\n",
    "        unique_shapes = set(stats['mask_shapes'])\n",
    "        for shape in unique_shapes:\n",
    "            count = stats['mask_shapes'].count(shape)\n",
    "            print(f\"  {shape}: {count} masks\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "\n",
    "def create_data_splits(\n",
    "    hdf5_path: Path,\n",
    "    output_dir: Path,\n",
    "    train_ratio: float = 0.70,\n",
    "    val_ratio: float = 0.15,\n",
    "    test_ratio: float = 0.15,\n",
    "    random_seed: int = 42,\n",
    "    stratify: bool = True\n",
    ") -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Create train/validation/test splits with optional stratification.\n",
    "    \n",
    "    Args:\n",
    "        hdf5_path: Path to HDF5 file\n",
    "        output_dir: Directory to save split files\n",
    "        train_ratio: Proportion for training set\n",
    "        val_ratio: Proportion for validation set\n",
    "        test_ratio: Proportion for test set\n",
    "        random_seed: Random seed for reproducibility\n",
    "        stratify: Whether to stratify by tumor type label\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with 'train', 'val', 'test' patient ID lists\n",
    "    \"\"\"\n",
    "    # Load all patient IDs and labels\n",
    "    patient_ids = []\n",
    "    labels = []\n",
    "    \n",
    "    with h5py.File(hdf5_path, 'r') as f:\n",
    "        for patient_id in f.keys():\n",
    "            patient_ids.append(patient_id)\n",
    "            labels.append(int(f[patient_id]['label'][()]))\n",
    "    \n",
    "    patient_ids = np.array(patient_ids)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Create splits\n",
    "    if stratify:\n",
    "        # First split: train vs (val + test)\n",
    "        train_ids, temp_ids, train_labels, temp_labels = train_test_split(\n",
    "            patient_ids, labels,\n",
    "            test_size=(val_ratio + test_ratio),\n",
    "            random_state=random_seed,\n",
    "            stratify=labels\n",
    "        )\n",
    "        \n",
    "        # Second split: val vs test\n",
    "        val_ratio_adjusted = val_ratio / (val_ratio + test_ratio)\n",
    "        val_ids, test_ids, val_labels, test_labels = train_test_split(\n",
    "            temp_ids, temp_labels,\n",
    "            test_size=(1 - val_ratio_adjusted),\n",
    "            random_state=random_seed,\n",
    "            stratify=temp_labels\n",
    "        )\n",
    "    else:\n",
    "        # Random split without stratification\n",
    "        train_ids, temp_ids = train_test_split(\n",
    "            patient_ids,\n",
    "            test_size=(val_ratio + test_ratio),\n",
    "            random_state=random_seed\n",
    "        )\n",
    "        \n",
    "        val_ratio_adjusted = val_ratio / (val_ratio + test_ratio)\n",
    "        val_ids, test_ids = train_test_split(\n",
    "            temp_ids,\n",
    "            test_size=(1 - val_ratio_adjusted),\n",
    "            random_state=random_seed\n",
    "        )\n",
    "    \n",
    "    splits = {\n",
    "        'train': train_ids.tolist(),\n",
    "        'val': val_ids.tolist(),\n",
    "        'test': test_ids.tolist()\n",
    "    }\n",
    "    \n",
    "    # Save splits to JSON files\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for split_name, ids in splits.items():\n",
    "        output_path = output_dir / f\"{split_name}_ids.json\"\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(ids, f, indent=2)\n",
    "    \n",
    "    # Print split statistics\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Data Split Summary\")\n",
    "    print(\"=\" * 60)\n",
    "    for split_name, ids in splits.items():\n",
    "        print(f\"{split_name.upper()}: {len(ids)} patients ({len(ids)/len(patient_ids)*100:.1f}%)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return splits\n",
    "\n",
    "\n",
    "def load_data_splits(splits_dir: Path) -> Dict[str, List[str]]:\n",
    "    \"\"\"Load previously created data splits.\"\"\"\n",
    "    splits = {}\n",
    "    for split_name in ['train', 'val', 'test']:\n",
    "        split_path = splits_dir / f\"{split_name}_ids.json\"\n",
    "        if split_path.exists():\n",
    "            with open(split_path, 'r') as f:\n",
    "                splits[split_name] = json.load(f)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Split file not found: {split_path}\")\n",
    "    return splits\n",
    "\n",
    "\n",
    "def create_dataloaders(\n",
    "    hdf5_path: Path,\n",
    "    splits: Dict[str, List[str]],\n",
    "    batch_size: int = 16,\n",
    "    num_workers: int = 4,\n",
    "    train_transform=None,\n",
    "    val_transform=None,\n",
    "    return_label: bool = False\n",
    ") -> Dict[str, DataLoader]:\n",
    "    \"\"\"\n",
    "    Create DataLoaders for train, validation, and test sets.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with 'train', 'val', 'test' DataLoaders\n",
    "    \"\"\"\n",
    "    datasets = {\n",
    "        'train': BrainTumorDataset(\n",
    "            hdf5_path, splits['train'],\n",
    "            transform=train_transform,\n",
    "            return_label=return_label\n",
    "        ),\n",
    "        'val': BrainTumorDataset(\n",
    "            hdf5_path, splits['val'],\n",
    "            transform=val_transform,\n",
    "            return_label=return_label\n",
    "        ),\n",
    "        'test': BrainTumorDataset(\n",
    "            hdf5_path, splits['test'],\n",
    "            transform=val_transform,\n",
    "            return_label=return_label\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    dataloaders = {\n",
    "        'train': DataLoader(\n",
    "            datasets['train'],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        ),\n",
    "        'val': DataLoader(\n",
    "            datasets['val'],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        ),\n",
    "        'test': DataLoader(\n",
    "            datasets['test'],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    return dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a59fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Image normalization methods for MRI brain images.\n",
    "\"\"\"\n",
    "\n",
    "def z_score_normalize(image: np.ndarray) -> Tuple[np.ndarray, float, float]:\n",
    "    \"\"\"\n",
    "    Z-score normalization: (pixel - mean) / std\n",
    "    \n",
    "    Args:\n",
    "        image: Input image\n",
    "    \n",
    "    Returns:\n",
    "        Normalized image, mean, std\n",
    "    \"\"\"\n",
    "    mean = np.mean(image)\n",
    "    std = np.std(image)\n",
    "    \n",
    "    if std == 0:\n",
    "        return image, mean, std\n",
    "    \n",
    "    normalized = (image - mean) / std\n",
    "    return normalized, mean, std\n",
    "\n",
    "\n",
    "def min_max_normalize(image: np.ndarray) -> Tuple[np.ndarray, float, float]:\n",
    "    \"\"\"\n",
    "    Min-max normalization: (pixel - min) / (max - min)\n",
    "    \n",
    "    Args:\n",
    "        image: Input image\n",
    "    \n",
    "    Returns:\n",
    "        Normalized image (0-1 range), min, max\n",
    "    \"\"\"\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    \n",
    "    if max_val == min_val:\n",
    "        return image, min_val, max_val\n",
    "    \n",
    "    normalized = (image - min_val) / (max_val - min_val)\n",
    "    return normalized, min_val, max_val\n",
    "\n",
    "\n",
    "def histogram_equalize(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Histogram equalization for contrast enhancement.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image (0-255 range expected)\n",
    "    \n",
    "    Returns:\n",
    "        Equalized image\n",
    "    \"\"\"\n",
    "    # Convert to uint8 if needed\n",
    "    if image.max() <= 1.0:\n",
    "        image_uint8 = (image * 255).astype(np.uint8)\n",
    "    else:\n",
    "        image_uint8 = image.astype(np.uint8)\n",
    "    \n",
    "    equalized = cv2.equalizeHist(image_uint8)\n",
    "    \n",
    "    # Convert back to float\n",
    "    return equalized.astype(np.float32) / 255.0 if image.max() <= 1.0 else equalized.astype(np.float32)\n",
    "\n",
    "\n",
    "def clahe_normalize(\n",
    "    image: np.ndarray,\n",
    "    clip_limit: float = 2.0,\n",
    "    tile_grid_size: Tuple[int, int] = (8, 8)\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Contrast Limited Adaptive Histogram Equalization (CLAHE).\n",
    "    \n",
    "    Args:\n",
    "        image: Input image (0-255 range expected)\n",
    "        clip_limit: Threshold for contrast limiting\n",
    "        tile_grid_size: Size of grid for histogram equalization\n",
    "    \n",
    "    Returns:\n",
    "        CLAHE normalized image\n",
    "    \"\"\"\n",
    "    # Convert to uint8 if needed\n",
    "    if image.max() <= 1.0:\n",
    "        image_uint8 = (image * 255).astype(np.uint8)\n",
    "    else:\n",
    "        image_uint8 = image.astype(np.uint8)\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    normalized = clahe.apply(image_uint8)\n",
    "    \n",
    "    # Convert back to float\n",
    "    return normalized.astype(np.float32) / 255.0 if image.max() <= 1.0 else normalized.astype(np.float32)\n",
    "\n",
    "\n",
    "def apply_normalization(\n",
    "    image: np.ndarray,\n",
    "    method: str = \"z_score\",\n",
    "    **kwargs\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply normalization using specified method.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image\n",
    "        method: Normalization method ('z_score', 'min_max', 'histogram_eq', 'clahe')\n",
    "        **kwargs: Additional arguments for specific normalization method\n",
    "    \n",
    "    Returns:\n",
    "        Normalized image\n",
    "    \"\"\"\n",
    "    methods = {\n",
    "        'z_score': lambda img: z_score_normalize(img)[0],\n",
    "        'min_max': lambda img: min_max_normalize(img)[0],\n",
    "        'histogram_eq': histogram_equalize,\n",
    "        'clahe': clahe_normalize\n",
    "    }\n",
    "    \n",
    "    if method not in methods:\n",
    "        raise ValueError(f\"Unknown normalization method: {method}. Choose from {list(methods.keys())}\")\n",
    "    \n",
    "    return methods[method](image, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loss functions for brain tumor segmentation.\n",
    "\"\"\"\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Dice Loss for binary segmentation.\n",
    "    Directly optimizes Dice Similarity Coefficient.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, smooth: float = 1e-6):\n",
    "        \"\"\"\n",
    "        Initialize Dice Loss.\n",
    "        \n",
    "        Args:\n",
    "            smooth: Smoothing factor to avoid division by zero\n",
    "        \"\"\"\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute Dice Loss.\n",
    "        \n",
    "        Args:\n",
    "            predictions: Predicted masks (B, 1, H, W) with values in [0, 1]\n",
    "            targets: Ground truth masks (B, 1, H, W) with values in [0, 1]\n",
    "        \n",
    "        Returns:\n",
    "            Dice loss value\n",
    "        \"\"\"\n",
    "        # Flatten tensors\n",
    "        predictions = predictions.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        # Compute intersection and union\n",
    "        intersection = (predictions * targets).sum()\n",
    "        dice = (2.0 * intersection + self.smooth) / (\n",
    "            predictions.sum() + targets.sum() + self.smooth\n",
    "        )\n",
    "        \n",
    "        # Return 1 - dice (loss to minimize)\n",
    "        return 1 - dice\n",
    "\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Combined Dice Loss and Binary Cross-Entropy Loss.\n",
    "    Often provides better training stability.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dice_weight: float = 0.5, bce_weight: float = 0.5, smooth: float = 1e-6):\n",
    "        \"\"\"\n",
    "        Initialize Combined Loss.\n",
    "        \n",
    "        Args:\n",
    "            dice_weight: Weight for Dice Loss\n",
    "            bce_weight: Weight for BCE Loss\n",
    "            smooth: Smoothing factor for Dice Loss\n",
    "        \"\"\"\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.dice_weight = dice_weight\n",
    "        self.bce_weight = bce_weight\n",
    "        self.dice_loss = DiceLoss(smooth=smooth)\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "    \n",
    "    def forward(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute combined loss.\n",
    "        \n",
    "        Args:\n",
    "            predictions: Predicted masks\n",
    "            targets: Ground truth masks\n",
    "        \n",
    "        Returns:\n",
    "            Combined loss value\n",
    "        \"\"\"\n",
    "        dice = self.dice_loss(predictions, targets)\n",
    "        bce = self.bce_loss(predictions, targets)\n",
    "        \n",
    "        return self.dice_weight * dice + self.bce_weight * bce\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss for handling class imbalance.\n",
    "    Useful when tumor regions are small compared to background.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 0.25, gamma: float = 2.0):\n",
    "        \"\"\"\n",
    "        Initialize Focal Loss.\n",
    "        \n",
    "        Args:\n",
    "            alpha: Weighting factor for rare class\n",
    "            gamma: Focusing parameter\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute Focal Loss.\n",
    "        \n",
    "        Args:\n",
    "            predictions: Predicted masks\n",
    "            targets: Ground truth masks\n",
    "        \n",
    "        Returns:\n",
    "            Focal loss value\n",
    "        \"\"\"\n",
    "        # Compute BCE\n",
    "        bce = F.binary_cross_entropy(predictions, targets, reduction='none')\n",
    "        \n",
    "        # Compute p_t\n",
    "        p_t = predictions * targets + (1 - predictions) * (1 - targets)\n",
    "        \n",
    "        # Compute focal weight\n",
    "        focal_weight = (1 - p_t) ** self.gamma\n",
    "        \n",
    "        # Apply alpha\n",
    "        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "        \n",
    "        # Compute focal loss\n",
    "        focal_loss = alpha_t * focal_weight * bce\n",
    "        \n",
    "        return focal_loss.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe75beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training utilities for brain tumor segmentation models.\n",
    "\"\"\"\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"Generic trainer for segmentation models.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        train_loader: torch.utils.data.DataLoader,\n",
    "        val_loader: torch.utils.data.DataLoader,\n",
    "        criterion: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        device: torch.device,\n",
    "        config,\n",
    "        model_name: str = \"model\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize trainer.\n",
    "        \n",
    "        Args:\n",
    "            model: Model to train\n",
    "            train_loader: Training data loader\n",
    "            val_loader: Validation data loader\n",
    "            criterion: Loss function\n",
    "            optimizer: Optimizer\n",
    "            device: Device to train on\n",
    "            config: Configuration object\n",
    "            model_name: Name for saving checkpoints\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.config = config\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='max',\n",
    "            factor=config.REDUCE_LR_FACTOR,\n",
    "            patience=config.REDUCE_LR_PATIENCE,\n",
    "            min_lr=config.MIN_LEARNING_RATE,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Mixed precision training\n",
    "        self.use_amp = config.USE_MIXED_PRECISION and hasattr(torch.cuda, 'amp')\n",
    "        if self.use_amp:\n",
    "            self.scaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "        # TensorBoard writer\n",
    "        log_dir = config.LOGS_DIR / model_name\n",
    "        self.writer = SummaryWriter(log_dir=str(log_dir))\n",
    "        \n",
    "        # Training state\n",
    "        self.current_epoch = 0\n",
    "        self.best_val_dice = 0.0\n",
    "        self.train_losses = []\n",
    "        self.val_dice_scores = []\n",
    "        \n",
    "        # Early stopping\n",
    "        self.patience_counter = 0\n",
    "        self.early_stopping_patience = config.EARLY_STOPPING_PATIENCE\n",
    "    \n",
    "    def train_epoch(self) -> float:\n",
    "        \"\"\"Train for one epoch.\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(self.train_loader):\n",
    "            images = batch['image'].to(self.device)\n",
    "            masks = batch['mask'].to(self.device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            if self.use_amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    predictions = self.model(images)\n",
    "                    loss = self.criterion(predictions, masks)\n",
    "                \n",
    "                # Backward pass\n",
    "                self.scaler.scale(loss).backward()\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "            else:\n",
    "                predictions = self.model(images)\n",
    "                loss = self.criterion(predictions, masks)\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            # Update statistics\n",
    "            running_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Logging\n",
    "            if batch_idx % self.config.LOG_INTERVAL == 0:\n",
    "                print(f'Epoch {self.current_epoch}, Batch {batch_idx}/{len(self.train_loader)}, '\n",
    "                      f'Loss: {loss.item():.4f}')\n",
    "                \n",
    "                # Log to TensorBoard\n",
    "                global_step = self.current_epoch * len(self.train_loader) + batch_idx\n",
    "                self.writer.add_scalar('Train/Loss', loss.item(), global_step)\n",
    "        \n",
    "        avg_loss = running_loss / num_batches\n",
    "        return avg_loss\n",
    "    \n",
    "    def validate(self) -> Dict[str, float]:\n",
    "        \"\"\"Validate model.\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        metrics = evaluate_model(self.model, self.val_loader, self.device)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def save_checkpoint(self, is_best: bool = False):\n",
    "        \"\"\"Save model checkpoint.\"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': self.current_epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'best_val_dice': self.best_val_dice,\n",
    "            'train_losses': self.train_losses,\n",
    "            'val_dice_scores': self.val_dice_scores\n",
    "        }\n",
    "        \n",
    "        if self.use_amp:\n",
    "            checkpoint['scaler_state_dict'] = self.scaler.state_dict()\n",
    "        \n",
    "        # Save latest checkpoint\n",
    "        checkpoint_path = self.config.SAVED_MODELS_DIR / f\"{self.model_name}_latest.pth\"\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        \n",
    "        # Save best checkpoint\n",
    "        if is_best:\n",
    "            best_path = self.config.SAVED_MODELS_DIR / f\"{self.model_name}_best.pth\"\n",
    "            torch.save(checkpoint, best_path)\n",
    "            print(f\"Saved best model with DSC: {self.best_val_dice:.4f}\")\n",
    "    \n",
    "    def load_checkpoint(self, checkpoint_path: Path):\n",
    "        \"\"\"Load model checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        \n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.current_epoch = checkpoint['epoch']\n",
    "        self.best_val_dice = checkpoint['best_val_dice']\n",
    "        self.train_losses = checkpoint.get('train_losses', [])\n",
    "        self.val_dice_scores = checkpoint.get('val_dice_scores', [])\n",
    "        \n",
    "        if self.use_amp and 'scaler_state_dict' in checkpoint:\n",
    "            self.scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "        \n",
    "        print(f\"Loaded checkpoint from epoch {self.current_epoch}\")\n",
    "    \n",
    "    def train(self, num_epochs: int, resume_from: Optional[Path] = None):\n",
    "        \"\"\"\n",
    "        Main training loop.\n",
    "        \n",
    "        Args:\n",
    "            num_epochs: Number of epochs to train\n",
    "            resume_from: Path to checkpoint to resume from\n",
    "        \"\"\"\n",
    "        if resume_from:\n",
    "            self.load_checkpoint(resume_from)\n",
    "        \n",
    "        print(f\"Starting training for {num_epochs} epochs...\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "        print(f\"Model parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(self.current_epoch, num_epochs):\n",
    "            self.current_epoch = epoch\n",
    "            \n",
    "            # Train\n",
    "            train_loss = self.train_epoch()\n",
    "            self.train_losses.append(train_loss)\n",
    "            \n",
    "            # Validate\n",
    "            val_metrics = self.validate()\n",
    "            val_dice = val_metrics['dice']\n",
    "            self.val_dice_scores.append(val_dice)\n",
    "            \n",
    "            # Update learning rate\n",
    "            self.scheduler.step(val_dice)\n",
    "            \n",
    "            # Check if best model\n",
    "            is_best = val_dice > self.best_val_dice\n",
    "            if is_best:\n",
    "                self.best_val_dice = val_dice\n",
    "                self.patience_counter = 0\n",
    "            else:\n",
    "                self.patience_counter += 1\n",
    "            \n",
    "            # Save checkpoint\n",
    "            if (epoch + 1) % self.config.SAVE_INTERVAL == 0 or is_best:\n",
    "                self.save_checkpoint(is_best=is_best)\n",
    "            \n",
    "            # Log epoch summary\n",
    "            print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"Val DSC: {val_dice:.4f}\")\n",
    "            print(f\"Val IoU: {val_metrics['iou']:.4f}\")\n",
    "            print(f\"Best Val DSC: {self.best_val_dice:.4f}\")\n",
    "            print(f\"LR: {self.optimizer.param_groups[0]['lr']:.6f}\")\n",
    "            \n",
    "            # Log to TensorBoard\n",
    "            self.writer.add_scalar('Epoch/Train_Loss', train_loss, epoch)\n",
    "            self.writer.add_scalar('Epoch/Val_Dice', val_dice, epoch)\n",
    "            self.writer.add_scalar('Epoch/Val_IoU', val_metrics['iou'], epoch)\n",
    "            self.writer.add_scalar('Epoch/Learning_Rate', self.optimizer.param_groups[0]['lr'], epoch)\n",
    "            \n",
    "            # Early stopping\n",
    "            if self.patience_counter >= self.early_stopping_patience:\n",
    "                print(f\"\\nEarly stopping triggered after {epoch + 1} epochs\")\n",
    "                break\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"\\nTraining completed in {training_time/60:.2f} minutes\")\n",
    "        print(f\"Best validation DSC: {self.best_val_dice:.4f}\")\n",
    "        \n",
    "        # Save final checkpoint\n",
    "        self.save_checkpoint(is_best=False)\n",
    "        self.writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d41a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pre-trained model architectures for brain tumor segmentation.\n",
    "Uses transfer learning with ResNet, VGG, or U-Net backbones.\n",
    "\"\"\"\n",
    "class ResNetUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net with ResNet encoder for brain tumor segmentation.\n",
    "    Uses pre-trained ResNet as encoder backbone.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_name: str = \"resnet50\",\n",
    "        pretrained: bool = True,\n",
    "        num_classes: int = 1,\n",
    "        dropout: float = 0.2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize ResNet-U-Net.\n",
    "        \n",
    "        Args:\n",
    "            encoder_name: ResNet variant ('resnet18', 'resnet34', 'resnet50', 'resnet101')\n",
    "            pretrained: Use ImageNet pre-trained weights\n",
    "            num_classes: Number of output classes (1 for binary segmentation)\n",
    "            dropout: Dropout rate\n",
    "        \"\"\"\n",
    "        super(ResNetUNet, self).__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet\n",
    "        resnet_models = {\n",
    "            'resnet18': models.resnet18,\n",
    "            'resnet34': models.resnet34,\n",
    "            'resnet50': models.resnet50,\n",
    "            'resnet101': models.resnet101\n",
    "        }\n",
    "        \n",
    "        if encoder_name not in resnet_models:\n",
    "            raise ValueError(f\"Unknown encoder: {encoder_name}\")\n",
    "        \n",
    "        encoder = resnet_models[encoder_name](pretrained=pretrained)\n",
    "        \n",
    "        # Encoder layers\n",
    "        self.encoder0 = nn.Sequential(\n",
    "            encoder.conv1,\n",
    "            encoder.bn1,\n",
    "            encoder.relu\n",
    "        )\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            encoder.maxpool,\n",
    "            encoder.layer1\n",
    "        )\n",
    "        self.encoder2 = encoder.layer2\n",
    "        self.encoder3 = encoder.layer3\n",
    "        self.encoder4 = encoder.layer4\n",
    "        \n",
    "        # Get channel sizes\n",
    "        if encoder_name in ['resnet18', 'resnet34']:\n",
    "            channels = [64, 64, 128, 256, 512]\n",
    "        else:  # resnet50, resnet101\n",
    "            channels = [64, 256, 512, 1024, 2048]\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder4 = self._make_decoder_block(channels[4], channels[3], dropout)\n",
    "        self.decoder3 = self._make_decoder_block(channels[3], channels[2], dropout)\n",
    "        self.decoder2 = self._make_decoder_block(channels[2], channels[1], dropout)\n",
    "        self.decoder1 = self._make_decoder_block(channels[1], channels[0], dropout)\n",
    "        self.decoder0 = self._make_decoder_block(channels[0], 64, dropout)\n",
    "        \n",
    "        # Output\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(dropout),\n",
    "            nn.Conv2d(32, num_classes, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def _make_decoder_block(self, in_channels: int, out_channels: int, dropout: float):\n",
    "        \"\"\"Create decoder block with upsampling and skip connections.\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(dropout),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e0 = self.encoder0(x)  # 64 channels\n",
    "        e1 = self.encoder1(e0)  # 64/256 channels\n",
    "        e2 = self.encoder2(e1)  # 128/512 channels\n",
    "        e3 = self.encoder3(e2)  # 256/1024 channels\n",
    "        e4 = self.encoder4(e3)  # 512/2048 channels\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        d4 = self.decoder4(e4)\n",
    "        d4 = F.interpolate(d4, size=e3.shape[2:], mode='bilinear', align_corners=True)\n",
    "        d4 = torch.cat([d4, e3], dim=1)\n",
    "        \n",
    "        d3 = self.decoder3(d4)\n",
    "        d3 = F.interpolate(d3, size=e2.shape[2:], mode='bilinear', align_corners=True)\n",
    "        d3 = torch.cat([d3, e2], dim=1)\n",
    "        \n",
    "        d2 = self.decoder2(d3)\n",
    "        d2 = F.interpolate(d2, size=e1.shape[2:], mode='bilinear', align_corners=True)\n",
    "        d2 = torch.cat([d2, e1], dim=1)\n",
    "        \n",
    "        d1 = self.decoder1(d2)\n",
    "        d1 = F.interpolate(d1, size=e0.shape[2:], mode='bilinear', align_corners=True)\n",
    "        d1 = torch.cat([d1, e0], dim=1)\n",
    "        \n",
    "        d0 = self.decoder0(d1)\n",
    "        \n",
    "        # Output\n",
    "        out = self.final_conv(d0)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class VGGUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net with VGG encoder for brain tumor segmentation.\n",
    "    Uses pre-trained VGG as encoder backbone.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_name: str = \"vgg16\",\n",
    "        pretrained: bool = True,\n",
    "        num_classes: int = 1,\n",
    "        dropout: float = 0.2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize VGG-U-Net.\n",
    "        \n",
    "        Args:\n",
    "            encoder_name: VGG variant ('vgg11', 'vgg13', 'vgg16', 'vgg19')\n",
    "            pretrained: Use ImageNet pre-trained weights\n",
    "            num_classes: Number of output classes\n",
    "            dropout: Dropout rate\n",
    "        \"\"\"\n",
    "        super(VGGUNet, self).__init__()\n",
    "        \n",
    "        # Load pre-trained VGG\n",
    "        vgg_models = {\n",
    "            'vgg11': models.vgg11,\n",
    "            'vgg13': models.vgg13,\n",
    "            'vgg16': models.vgg16,\n",
    "            'vgg19': models.vgg19\n",
    "        }\n",
    "        \n",
    "        if encoder_name not in vgg_models:\n",
    "            raise ValueError(f\"Unknown encoder: {encoder_name}\")\n",
    "        \n",
    "        vgg = vgg_models[encoder_name](pretrained=pretrained)\n",
    "        features = list(vgg.features.children())\n",
    "        \n",
    "        # Encoder blocks\n",
    "        self.encoder1 = nn.Sequential(*features[0:4])   # 64 channels\n",
    "        self.encoder2 = nn.Sequential(*features[4:9])   # 128 channels\n",
    "        self.encoder3 = nn.Sequential(*features[9:16])  # 256 channels\n",
    "        self.encoder4 = nn.Sequential(*features[16:23]) # 512 channels\n",
    "        self.encoder5 = nn.Sequential(*features[23:30]) # 512 channels\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder5 = self._make_decoder_block(512, 512, dropout)\n",
    "        self.decoder4 = self._make_decoder_block(512, 256, dropout)\n",
    "        self.decoder3 = self._make_decoder_block(256, 128, dropout)\n",
    "        self.decoder2 = self._make_decoder_block(128, 64, dropout)\n",
    "        self.decoder1 = self._make_decoder_block(64, 64, dropout)\n",
    "        \n",
    "        # Output\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(dropout),\n",
    "            nn.Conv2d(32, num_classes, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def _make_decoder_block(self, in_channels: int, out_channels: int, dropout: float):\n",
    "        \"\"\"Create decoder block.\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(dropout),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.encoder1(x)  # 64\n",
    "        e2 = self.encoder2(e1)  # 128\n",
    "        e3 = self.encoder3(e2)  # 256\n",
    "        e4 = self.encoder4(e3)  # 512\n",
    "        e5 = self.encoder5(e4)  # 512\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        d5 = self.decoder5(e5)\n",
    "        d5 = F.interpolate(d5, size=e4.shape[2:], mode='bilinear', align_corners=True)\n",
    "        d5 = torch.cat([d5, e4], dim=1)\n",
    "        \n",
    "        d4 = self.decoder4(d5)\n",
    "        d4 = F.interpolate(d4, size=e3.shape[2:], mode='bilinear', align_corners=True)\n",
    "        d4 = torch.cat([d4, e3], dim=1)\n",
    "        \n",
    "        d3 = self.decoder3(d4)\n",
    "        d3 = F.interpolate(d3, size=e2.shape[2:], mode='bilinear', align_corners=True)\n",
    "        d3 = torch.cat([d3, e2], dim=1)\n",
    "        \n",
    "        d2 = self.decoder2(d3)\n",
    "        d2 = F.interpolate(d2, size=e1.shape[2:], mode='bilinear', align_corners=True)\n",
    "        d2 = torch.cat([d2, e1], dim=1)\n",
    "        \n",
    "        d1 = self.decoder1(d2)\n",
    "        \n",
    "        # Output\n",
    "        out = self.final_conv(d1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "def get_pretrained_model(\n",
    "    model_type: str = \"resnet\",\n",
    "    encoder_name: str = \"resnet50\",\n",
    "    pretrained: bool = True,\n",
    "    num_classes: int = 1,\n",
    "    dropout: float = 0.2\n",
    "):\n",
    "    \"\"\"\n",
    "    Factory function to get pre-trained model.\n",
    "    \n",
    "    Args:\n",
    "        model_type: Model type ('resnet', 'vgg')\n",
    "        encoder_name: Encoder name (e.g., 'resnet50', 'vgg16')\n",
    "        pretrained: Use pre-trained weights\n",
    "        num_classes: Number of output classes\n",
    "        dropout: Dropout rate\n",
    "    \n",
    "    Returns:\n",
    "        Model instance\n",
    "    \"\"\"\n",
    "    if model_type.lower() == \"resnet\":\n",
    "        return ResNetUNet(encoder_name, pretrained, num_classes, dropout)\n",
    "    elif model_type.lower() == \"vgg\":\n",
    "        return VGGUNet(encoder_name, pretrained, num_classes, dropout)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b1aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training script for pre-trained brain tumor segmentation model.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398a5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    \"\"\"Main training function.\"\"\"\n",
    "    # Initialize configuration\n",
    "    config = Config()\n",
    "    config.create_directories()\n",
    "    \n",
    "    # Set random seeds for reproducibility\n",
    "    torch.manual_seed(config.RANDOM_SEED)\n",
    "    torch.cuda.manual_seed_all(config.RANDOM_SEED)\n",
    "    import numpy as np\n",
    "    np.random.seed(config.RANDOM_SEED)\n",
    "    import random\n",
    "    random.seed(config.RANDOM_SEED)\n",
    "    \n",
    "    # Device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Explore dataset\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Exploring Dataset\")\n",
    "    print(\"=\"*60)\n",
    "    path = config.HDF5_DATASET_PATH if config.ENVIRONMENT == \"local\" else config.get_data_from_google_drive()\n",
    "    explorer = HDF5DatasetExplorer(path)\n",
    "    explorer.print_summary()\n",
    "    \n",
    "    # Create or load data splits\n",
    "    splits_dir = config.SPLITS_DIR\n",
    "    if not (splits_dir / \"train_ids.json\").exists():\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Creating Data Splits\")\n",
    "        print(\"=\"*60)\n",
    "        splits = create_data_splits(\n",
    "            config.HDF5_DATASET_PATH,\n",
    "            splits_dir,\n",
    "            train_ratio=config.TRAIN_SPLIT,\n",
    "            val_ratio=config.VAL_SPLIT,\n",
    "            test_ratio=config.TEST_SPLIT,\n",
    "            random_seed=config.RANDOM_SEED,\n",
    "            stratify=True\n",
    "        )\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Loading Existing Data Splits\")\n",
    "        print(\"=\"*60)\n",
    "        splits = load_data_splits(splits_dir)\n",
    "        for split_name, ids in splits.items():\n",
    "            print(f\"{split_name.upper()}: {len(ids)} patients\")\n",
    "    \n",
    "    # Create transforms\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Setting up Preprocessing and Augmentation\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    preprocessing = PreprocessingTransform(\n",
    "        target_size=config.IMAGE_SIZE,\n",
    "        denoising_method=config.DENOISING_METHOD,\n",
    "        normalization_method=config.NORMALIZATION_METHOD\n",
    "    )\n",
    "    \n",
    "    augmentation = AugmentationTransform(\n",
    "        rotation_range=config.ROTATION_RANGE,\n",
    "        translation_range=config.TRANSLATION_RANGE,\n",
    "        scale_range=config.SCALE_RANGE,\n",
    "        brightness_range=config.BRIGHTNESS_RANGE,\n",
    "        contrast_range=config.CONTRAST_RANGE,\n",
    "        flip_probability=config.FLIP_PROBABILITY\n",
    "    ) if config.AUGMENTATION_ENABLED else None\n",
    "    \n",
    "    # Compose transforms\n",
    "    def train_transform(sample):\n",
    "        sample = preprocessing(sample)\n",
    "        if augmentation:\n",
    "            sample = augmentation(sample)\n",
    "        return sample\n",
    "    \n",
    "    # Create data loaders\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Creating Data Loaders\")\n",
    "    print(\"=\"*60)\n",
    "    dataloaders = create_dataloaders(\n",
    "        config.HDF5_DATASET_PATH,\n",
    "        splits,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "        train_transform=train_transform,\n",
    "        val_transform=preprocessing,\n",
    "        return_label=False\n",
    "    )\n",
    "    \n",
    "    print(f\"Train batches: {len(dataloaders['train'])}\")\n",
    "    print(f\"Val batches: {len(dataloaders['val'])}\")\n",
    "    print(f\"Test batches: {len(dataloaders['test'])}\")\n",
    "    \n",
    "    # Create model\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Creating Pre-trained Model\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Determine model type and encoder\n",
    "    if config.PRETRAINED_MODEL_TYPE.lower() == \"resnet\":\n",
    "        model_type = \"resnet\"\n",
    "        encoder_name = config.PRETRAINED_ENCODER\n",
    "    elif config.PRETRAINED_MODEL_TYPE.lower() == \"vgg\":\n",
    "        model_type = \"vgg\"\n",
    "        encoder_name = \"vgg16\"  # Default VGG\n",
    "    else:\n",
    "        model_type = \"resnet\"\n",
    "        encoder_name = \"resnet50\"\n",
    "    \n",
    "    model = get_pretrained_model(\n",
    "        model_type=model_type,\n",
    "        encoder_name=encoder_name,\n",
    "        pretrained=True,\n",
    "        num_classes=1,\n",
    "        dropout=config.DROPOUT_RATE\n",
    "    ).to(device)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = DiceLoss(smooth=1e-6)\n",
    "    # Alternative: CombinedLoss(dice_weight=0.5, bce_weight=0.5)\n",
    "    \n",
    "    # Optimizer with differential learning rates\n",
    "    # Lower LR for encoder (pre-trained), higher for decoder (new)\n",
    "    encoder_params = []\n",
    "    decoder_params = []\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'encoder' in name:\n",
    "            encoder_params.append(param)\n",
    "        else:\n",
    "            decoder_params.append(param)\n",
    "    \n",
    "    optimizer = optim.Adam([\n",
    "        {'params': encoder_params, 'lr': config.LEARNING_RATE * 0.1},  # 10x lower LR for encoder\n",
    "        {'params': decoder_params, 'lr': config.LEARNING_RATE}\n",
    "    ], weight_decay=config.WEIGHT_DECAY)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=dataloaders['train'],\n",
    "        val_loader=dataloaders['val'],\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        config=config,\n",
    "        model_name=f\"pretrained_{model_type}_{encoder_name}\"\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Starting Training\")\n",
    "    print(\"=\"*60)\n",
    "    trainer.train(num_epochs=config.NUM_EPOCHS)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Training Complete!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Best validation DSC: {trainer.best_val_dice:.4f}\")\n",
    "    print(f\"Model saved to: {config.SAVED_MODELS_DIR}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a372104",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a36a86",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
